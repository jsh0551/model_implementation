{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "cfg = ({'batch_size': 64,\n",
    "        'epoch' : 40,\n",
    "        'lr' : 1e-4\n",
    "        })\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(0.5,1.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../.data'\n",
    "\n",
    "train_dataset = datasets.MNIST(root,transform=transform,train=True,download=True)\n",
    "test_dataset = datasets.MNIST(root,transform=transform,train=False,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=cfg['batch_size'], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=cfg['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JSH\\Desktop\\MyGithub\\paper_implementation\\.paper_venv\\lib\\site-packages\\torchvision\\datasets\\mnist.py:65: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "from AE import AutoEncoder, VAE, VAE_Loss, CVAE, CVAE_Loss\n",
    "model = CVAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2, c_dim=train_loader.dataset.train_labels.unique().size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=cfg['lr'])\n",
    "\n",
    "model.eval()\n",
    "for epoch in tqdm(range(cfg['epoch'])):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x,label in tqdm(train_loader):\n",
    "        x = x.to(device).view(-1,28*28)\n",
    "        y = x.to(device).view(-1,28*28)\n",
    "        label = label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        encoded,decoded = model(x)\n",
    "\n",
    "        loss = criterion(decoded,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss\n",
    "    print(f'train_loss : {train_loss}')\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for image,label in tqdm(test_loader):\n",
    "            x = x.to(device).view(-1,28*28)\n",
    "            y = x.to(device).view(-1,28*28)\n",
    "            label = label.to(device)\n",
    "\n",
    "            encoded,output = model(x)\n",
    "\n",
    "            loss = criterion(output,y)\n",
    "            val_loss += loss\n",
    "        print(f'valid_loss : {val_loss}')\n",
    "        f, a = plt.subplots(2, 5, figsize=(5, 2))\n",
    "        print(f'{epoch+1} epoch completed') \n",
    "        for i in range(5):\n",
    "            img = np.reshape(x.data.to(\"cpu\").numpy()[i],(28, 28))\n",
    "            a[0][i].imshow(img, cmap='gray')\n",
    "            a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
    "\n",
    "        for i in range(5):\n",
    "            img = np.reshape(output.to(\"cpu\").data.numpy()[i], (28, 28)) \n",
    "\n",
    "            a[1][i].imshow(img, cmap='gray')\n",
    "            a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba55624f8f5dfc5da202e05117f540c3b5c190fa8630c7fe4435eb273edcce18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
